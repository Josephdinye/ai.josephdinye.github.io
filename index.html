<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Joseph's AI Chat</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" />
  <style>
    body { font-family: Arial, sans-serif; margin: 0; background: #f0f2f5; height: 100vh; display: flex; flex-direction: column; }
    #chat-container { flex: 1; max-width: 800px; margin: auto; background: white; border-radius: 10px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); overflow: hidden; display: flex; flex-direction: column; }
    #messages { flex: 1; overflow-y: auto; padding: 15px; }
    .message { margin: 10px 0; padding: 10px 15px; border-radius: 18px; max-width: 80%; position: relative; }
    .user { background: #0084ff; color: white; margin-left: auto; }
    .bot { background: #e5e5ea; color: black; }
    .attachment { margin-top: 8px; max-width: 200px; }
    .attachment img { max-width: 100%; border-radius: 8px; }
    .attachment a { color: #0084ff; text-decoration: none; }
    #input-area { display: flex; align-items: center; padding: 10px; border-top: 1px solid #ddd; background: #f9f9f9; }
    #user-input { flex: 1; padding: 12px; border: 1px solid #ccc; border-radius: 20px; margin: 0 8px; font-size: 16px; }
    button { background: none; border: none; font-size: 20px; cursor: pointer; padding: 8px; color: #0084ff; }
    button:hover { opacity: 0.8; }
    #loading { display: none; text-align: center; padding: 10px; color: #666; }
    .mic-active { color: red !important; animation: pulse 1.5s infinite; }
    @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.2); } 100% { transform: scale(1); } }
  </style>
</head>
<body>

<div id="chat-container">
  <div id="messages"></div>
  <div id="loading">Thinking...</div>
  <div id="input-area">
    <button id="voice-btn" title="Talk to AI (voice input)"><i class="fas fa-microphone"></i></button>
    <input id="user-input" type="text" placeholder="Ask me anything..." autocomplete="off"/>
    <label for="file-input" title="Upload file (image/PDF/text)">
      <button><i class="fas fa-paperclip"></i></button>
    </label>
    <input id="file-input" type="file" accept="image/*,.pdf,.txt,.doc,.docx" hidden />
    <button onclick="sendMessage()" title="Send"><i class="fas fa-paper-plane"></i></button>
  </div>
</div>

<script>
  const API_KEY = "sk-p81CFfNzDHTE7kP9kXwMynebya5nn";  // ← Replace with real key (or use proxy!)
  const MODEL = "llama-3.1-70b-versatile";   // or vision model like "llava-v1.5-7b-4096-preview" for images

  let recognition = null;
  let isListening = false;
  let currentFile = null;
  let currentFileName = "";
  let currentFilePreview = "";

  // Speech Recognition (Voice Input)
  if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = false;      // Stop after one phrase
    recognition.interimResults = false;  // Final results only
    recognition.lang = 'en-US';          // Change to your language, e.g. 'ru-RU'

    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript.trim();
      document.getElementById("user-input").value = transcript;
      sendMessage();  // Auto-send after voice input (optional — remove if you want manual send)
    };

    recognition.onerror = (event) => {
      console.error("Voice error:", event.error);
      alert("Voice input error: " + event.error + ". Try again or type manually.");
      stopListening();
    };

    recognition.onend = stopListening;
  } else {
    document.getElementById("voice-btn").disabled = true;
    document.getElementById("voice-btn").title = "Voice not supported in this browser";
  }

  function startListening() {
    if (!recognition) return;
    isListening = true;
    document.getElementById("voice-btn").classList.add("mic-active");
    recognition.start();
  }

  function stopListening() {
    isListening = false;
    document.getElementById("voice-btn").classList.remove("mic-active");
    if (recognition) recognition.stop();
  }

  document.getElementById("voice-btn").addEventListener("click", () => {
    if (isListening) stopListening();
    else startListening();
  });

  // File Upload + Preview
  document.getElementById("file-input").addEventListener("change", (e) => {
    const file = e.target.files[0];
    if (!file) return;

    currentFile = file;
    currentFileName = file.name;

    const reader = new FileReader();
    reader.onload = (ev) => {
      if (file.type.startsWith("image/")) {
        currentFilePreview = ev.target.result; // base64 for preview
        addMessage("You uploaded: " + currentFileName, true);
        const img = document.createElement("img");
        img.src = currentFilePreview;
        img.className = "attachment";
        document.getElementById("messages").lastChild.appendChild(img);
      } else {
        currentFilePreview = ""; // No preview for non-images
        addMessage("You uploaded file: " + currentFileName, true);
      }
    };
    if (file.type.startsWith("image/")) reader.readAsDataURL(file);
    else reader.readAsDataURL(file); // Still read for potential future use
  });

  function addMessage(text, isUser = false, extraHtml = "") {
    const div = document.createElement("div");
    div.className = `message ${isUser ? "user" : "bot"}`;
    div.innerHTML = text + extraHtml;
    document.getElementById("messages").appendChild(div);
    div.scrollIntoView();
  }

  async function sendMessage() {
    const input = document.getElementById("user-input");
    let text = input.value.trim();
    if (!text && !currentFile) return;

    let messageText = text;
    if (currentFileName) {
      messageText += ` [Attached: ${currentFileName}]`;
    }

    addMessage(messageText, true);
    input.value = "";
    currentFile = null;
    currentFileName = "";
    currentFilePreview = "";

    document.getElementById("loading").style.display = "block";

    try {
      const payload = {
        model: MODEL,
        messages: [{ role: "user", content: text }],
        temperature: 0.7,
        max_tokens: 500
      };

      // If you want image analysis later (with vision model):
      // if (currentFilePreview) payload.messages[0].content = [{ type: "text", text }, { type: "image_url", image_url: { url: currentFilePreview } }];

      const res = await fetch("https://https://groq-proxy-ai.josephdinye9.workers.dev/chat/completions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify(payload)
      });

      if (!res.ok) {
        const err = await res.json();
        throw new Error(err.error?.message || `HTTP ${res.status}`);
      }

      const data = await res.json();
      const reply = data.choices[0].message.content;
      addMessage(reply);
    } catch (err) {
      addMessage("Error: " + err.message);
      console.error(err);
    } finally {
      document.getElementById("loading").style.display = "none";
    }
  }

  // Send on Enter
  document.getElementById("user-input").addEventListener("keypress", e => {
    if (e.key === "Enter") sendMessage();
  });

  // Welcome
  addMessage("Hi! I'm your AI assistant powered by Joseph Ask me anything!.");
</script>
</body>
</html>
